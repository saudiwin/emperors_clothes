---
title: "Response to Reviewers for Measuring the Emperor's Clothes"
date: last-modified
date-format: long
fig-cap-location: top
author:
  - name: Robert Kubinec
    corresponding: true
    affiliation:
      - ref: usc
    email: rkubinec@mailbox.sc.edu
  - name: Amr Yakout
    affiliation:
      - ref: georgetown
affiliations:
  - id: georgetown
    name: Georgetown University
    city: Washington
    state: DC
    country: United States of America
  - id: usc
    name: University of South Carolina
    city: Columbia
    state: South Carolina
    country: United States of America
format: 
  wordcount-pdf:
    keep-tex: true
    toc: false
    include-in-header: 
      - text: |
          \usepackage{threeparttable}
          \usepackage{ragged2e}
  docx: default
always_allow_html: yes
extract-media: figures
#filters:
# - authors-block
number-sections: true
indent: true
editor: visual
linestretch: 1.5
bibliography: references.bib
execute: 
  cache: false
  echo: false
  warning: false
---

Dear Prof. Salloukh,

We thank you for the opportunity to revise our manuscript. We have made extensive revisions to the manuscript that we detail below in response to each reviewer. We hope that this revised manuscript will be suitable for publication in **Middle East Law and Governance**.

Regards,

Robert Kubinec & Amr Yakout

# Reviewer 1

1.  *The author should make clear that the methodologies she is exploring are designed to gather data for characterizing populations. They are of limited value for individual-level analysis.*

The reviewer is correct that this is a feature of sensitive survey designs. We have added the following language to our draft in the discussion:

"It is important to note that sensitive-survey designs are by nature able to capture population-level trends. That is, we are able to estimate with reasonable accuracy how many Tunisians on average oppose President Saied; in general we cannot make any confident claims about which individuals in our survey either support or oppose him."

2.  *So, surveys are probably the more common technique with which the Randomized Response Technique (RRT) should be compared. Ideally, both list experiments and straightforward asking of a sensitive questions should be compared to the RRT. And then, we see by page 14 that the comparison actually is with a direct question on a public opinion survey. This should be incorporated into the discussion of list experiments and alternatives to RRT.*

We note that this comment is substantively similar to a concern from reviewer 2 that we have framed our paper around list experiments, but we do not in fact test list experiments. For these reasons, we have changed sections of our introduction and abstract to de-emphasize list experiments and instead be sure to clarify what our actual analysis. We note that we do not test the list experiment directly against the RRT because there is already excellent experimental work on this question (see @rosenfeld2016), and in addition, evaluating sensitive survey techniques against each other and a direct question requires enormous sample sizes. For example, we include the following paragraph in the background section of the article:

"Our aim in this paper is not to compare randomized response to a list experiment directly as there is already excellent work on that question (see \@rosenfeld2016 in particular). To our knowledge, the reason that list experiments have become the dominant method is because other methods like randomized response are very difficult to incorporate in a survey because they may require extensive interviewer training and physical randomization devices. For that reason, our aim in this paper is to show how a particular variant of the randomized response technique that we describe below fits the study of public opinion quite well using modern survey procedures."

"There may of course be situations where a list experiment can perform better than a randomized response design, and other situations where only a list experiment is practical, such as with a verbal phone survey. However, we believe that expanding the toolkit available to scholars will only help to address this important issue of survey bias, and we show in this paper why a particular variant of randomized response is well-suited to the issue of political authoritarianism."

3.  *The explanation of RRT on page 8 is a little hard to follow. Also, in selecting RRT as the better way to determine whether a respondents oppose a dictator, among other sensitive topics, it treats the latter as a dichotomous variable, which then fails to capture a lot of the variance (intensity) in opposition-support. So, RRT is not without important limitations.*

We have worked to simplify this section and to add additional clarification on the nature of an RRT, which we agree is a non-intuitive concept. We also agree with the reviewer that the RRT is defined over binary variables, which leads to the noted limitation. We have added that limitation to our discussion of RRT.

4.  *The findings about covariates offer a useful test of the reliability of the descriptive findings, although the author's claims may be over-optimistic given that results are not statistically significant. The finding that self-censorship was primarily among more moderate opponents of Saied (the Tunisian president) is particularly interesting, and I agree with the author that "this intriguing relationship necessarily invites speculation as to the underlying causal process.”*

We agree with the reviewer that our findings should be caveated as some of them are fairly noisy. We have added the following sentence to our discussion of the results:

"However, it is important to note that there is substantial noise in these findings with confidence intervals that cross zero, and for that reason should be interpreted with caution."

## Reviewer 2

1.  *I strongly recommend that the authors de-emphasize list experiments in the abstract and framing. While the paper clearly presents the RRT approach as an alternative to list experiments—and makes a compelling case for its advantages—the current framing raises expectations that these claims will be demonstrated empirically. Given that no list experiment was fielded, some of the language in the abstract and introduction should be softened to avoid this impression.*

We agree with the reviewer, and as we have also noted with reviewer 1, we have de-emphasized the list experiment in this draft of the paper. We still discuss the list experiment in the background section as it is an important alternative method to the one that we present, but we removed any language that suggested that we were directly testing different sensitivity bias methods.

2.  *Some language may be overly loaded with assumptions or unnecessary normative statements about the region or Tunisia. One example appears on p. 13, where Tunisia is described as having "a once-bright future as an emerging democracy" prior to the autogolpe. While discussion of this history is appropriate, the language should stick more closely to observable facts. It is not clear that we can confidently characterize Tunisia's future as "bright," particularly given the significant challenges it faced.*

We have changed language in our discussion of Tunisia's democracy to be less normative and more factual. We have changed the sentence that the reviewer mentioned to the following:

"Tunisia, which some observers thought was on a steady path to a consolidated democracy in the 2010s, succumbed to an autogolpe (self-coup) when President Saied shut down the country's elected parliament in 2021."

3.  *What are some of the shortcomings of the RRT method as implemented here? While the authors are commendably transparent, I would welcome a more explicit discussion of potential downsides. Based on my own experience with sensitive survey tools—including list experiments—respondents are sometimes wary that some kind of "trick" is being used, which can affect both response behavior and willingness to answer. The authors note that there are substantially more missing responses to the sensitive question than to the direct question, and skepticism toward the method may contribute to this missingness in addition to cognitive load.*

We agree with the reviewer that there are downsides to using sensitive question formats. We have added a discussion of limitations of the method in our discussion section, and we reproduce the relevant paragraph below:

"While the RRT design makes use of assumptions that are easier to defend in this context than the list experiment, it does still make assumptions. The foremost assumption is that the randomizing device effectively encrypts the respondent's answer. If the respondent does not believe this--regardless of the sources of this belief--than the RRT will fail to capture the true latent trait. As we have previously mentioned, one advantage of the RRT with authoritarian opinion polling is that the direction of this bias is known--it will deflate the estimate of opposition to the authoritarian leader. For these reasons, while it is important to remember this assumption, it is nonetheless quite helpful for inference that the bias tends to be conservative."

"Additionally, RRTs, along with all sensitive question designs, require more cognitive effort from the respondent to understand, and consequently higher rates of missingness. It is not possible to measure this bias without also employing a direct question as we do in this paper, though we note that this procedure can come at considerable cost in terms of power. However, we note that while the rate of missingness is higher for the RRT question we employ, it is still low in objective terms at 6%. If the missingness rate were considerably higher, then it might be worthwhile to consider employing a direct question even there is residual sensitivity bias."

4. *R2: (N.B. While the number of missing responses may be relatively low, could this be context dependent? Do we have reason to believe that a list experiment, for example, would have produced lower non-response rates in this setting?)*

We do not have any way in our study of probing missing data more rigorously. At a minimum, we would have to vary the context (such as employing the survey in other countries) to know what the plausible range of missingness rates are. For these reasons, given our limited knowledge, we are unable to provide a more informative response to the reviewer's question than what we wrote in our previous response.

5. *R2: -A small table summarizing the main tools available for estimating sensitivity bias or eliciting preferences on sensitive questions could be useful, either near the end of the Background section or at the beginning of the Our Approach section. Such a table could briefly outline each method along with its advantages and drawbacks.*

We thank the reviewer for this suggestion and we have indeed added such a table in our background section.

6. *What does the Tunisian case represent with respect to repression of political speech? Even after the autogolpe, Tunisia is not among the most repressive states in this domain. This matters both for interpreting the magnitude of sensitivity bias and for contextualizing the Tunisia-specific findings. In more repressive contexts, one might expect those who are most opposed to be more likely to falsify their preferences. The Case Selection section should situate Tunisia relative to other states in the region, and the Discussion section could further contextualize the findings.*

We agree with the reviewer that other states in the region, such as the United Arab Emirates, have more effective repressive tools at their disposal to silence political dissent. 

We have added the following information to our case study:

And the following to our discussion section:

7. *Relatedly, the Discussion section could do more to highlight the paper's most interesting results. If sensitivity bias is highest among those who are moderately opposed, how might this bias our understanding of the characteristics of regime opponents? There is considerable room for elaboration here.*

We have expanded our discussion of this finding considerably with relation to recent work by Shammaileh (2025). In particular, we note an intriguing connection between Shammaileh's formal model of sensitivity survey bias and our empirical relationship concerning the strength of opposition to Saied. Shammaileh's model predicts that, indeed, sensitivity bias should increase highest for those who are closer to the dictator's ideal point, and less quickly the farther the respondent is from the dictator.

The full analysis is as follows:

8. *"Self-censorship" can be defined in multiple ways. A brief clarification of how the authors define this concept would be helpful.*

We have added a definition of self-censorship to our background section as follows:

9. *Finally, given the venue, the authors might consider briefly highlighting that scholars of the region have made important methodological contributions in this area, whether through work on list experiments, sensitivity bias in surveys, or qualitative research on how context shapes data quality. A short paragraph in the introduction or background section could acknowledge this literature, though this is not really necessary.*

We note that we have cited scholars working in or on the region, and in this draft we have made sure to highlight their specific contributions in our background section.